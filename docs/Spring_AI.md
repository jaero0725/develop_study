## 프롬프트 엔지니어링 패턴
### LLM 출력 구구성
#### 스프링 AI는 ChatOption 빌더로 구성옵션을 제어함
- 온도 : 모델응담의 무작위성 또는 창의성을 제어함. 1에 가까울수록 차의적, 0에 가까울수록 사실적임 
- 출력길이 : 모델이 생성할 수 잇는 최대 토큰 수를 제한함. 간결한 응답을 얻으려면 적절한 값을 택해야함
- 샘플링 컨트롤 : Top-K는 토큰 선택을 다음 토큰의 가능성이 가장 높은 K로 제한하며 값이 높을수록 다양성이 커짐
- 구조화 응답형식 : LLM응답을 자바객체에 매핑(Json, 객체형식으로 받을 수 있다)
- 모델별 옵션 : LLM제공 업체별로 차이나는 옵션들
